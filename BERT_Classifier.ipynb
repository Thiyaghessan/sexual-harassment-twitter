{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT Classifier",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1Fvm-adpXIsa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.util import ngrams\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from collections import defaultdict\n",
        "from collections import  Counter\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "import gensim\n",
        "import string\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tqdm import tqdm\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding,LSTM,Dense,SpatialDropout1D\n",
        "from keras.initializers import Constant\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import GlobalMaxPooling1D\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from transformers import BertTokenizer, TFBertModel, BertConfig, TFBertForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/data/final_labels.csv')"
      ],
      "metadata": {
        "id": "Qhp8BhZ1btcW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = data[data['body'].notna()]"
      ],
      "metadata": {
        "id": "IQDYxn4aYNDc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = data[data['body'].str.len() < 200]"
      ],
      "metadata": {
        "id": "Sg-KWb-1cGtG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data['body']\n",
        "\n",
        "label = LabelEncoder()\n",
        "y = label.fit_transform(data['level_1'])"
      ],
      "metadata": {
        "id": "r0c6kAAAckdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_dev, y_train, y_dev = train_test_split(X, y, train_size = 0.8, random_state = 42)\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_dev, y_dev, train_size = 0.5, random_state = 42)"
      ],
      "metadata": {
        "id": "1U1KIf2ZAy-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case = True)"
      ],
      "metadata": {
        "id": "uR3a6MIbA2e2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tensor_inputs(tweets, max_len = 200): \n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "  i = 0\n",
        "  for tweet in tweets: \n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "        tweet, \n",
        "        add_special_tokens = True, \n",
        "        max_length = max_len, \n",
        "        pad_to_max_length = True, \n",
        "        return_attention_mask = True\n",
        "    )\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "  input_ids = tf.convert_to_tensor(input_ids)\n",
        "  attention_masks = tf.convert_to_tensor(attention_masks)\n",
        "\n",
        "  return input_ids, attention_masks"
      ],
      "metadata": {
        "id": "XkDEAI1JA4zG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_inp, train_mask = inputs(X_train)\n",
        "val_inp, val_mask = inputs(X_valid)\n",
        "train_label = tf.convert_to_tensor(y_train)\n",
        "val_label = tf.convert_to_tensor(y_valid)"
      ],
      "metadata": {
        "id": "a96IQyP9A8cY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels = 2)"
      ],
      "metadata": {
        "id": "91HCBY8tBCUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir = '/content/drive/My Drive/Colab Notebooks/data/CS122'\n",
        "model_save = '/content/drive/My Drive/Colab Notebooks/data/CS122/cs122bert_test.h5'\n",
        "\n",
        "callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath=model_save,\n",
        "                                                save_weights_only = True,\n",
        "                                                monitor = 'val_loss',\n",
        "                                                mode = 'min', \n",
        "                                                save_best_only = True), \n",
        "             keras.callbacks.TensorBoard(log_dir = dir)]\n",
        "\n",
        "print('\\nBert Model', bert.summary())\n",
        "\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.00002, epsilon = 1e-08)\n",
        "\n",
        "bert.compile(loss=loss, optimizer=optimizer, metrics = [metric])"
      ],
      "metadata": {
        "id": "yOWBLoJ-BFDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "misogynist = bert.fit([train_inp, train_mask],\n",
        "                      train_label, \n",
        "                      batch_size = 32, \n",
        "                      epochs = 4, \n",
        "                      validation_data = ([val_inp, val_mask], val_label), \n",
        "                      callbacks = callbacks)"
      ],
      "metadata": {
        "id": "lch0dbdjBNrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_input, _ = tensor_inputs(X_test) "
      ],
      "metadata": {
        "id": "81sqyuv4BQm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred = bert.predict(test_input)"
      ],
      "metadata": {
        "id": "UlT4UlPPBY8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_prediction = tf.nn.softmax(test_pred.logits)\n",
        "test_prediction = tf.argmax(test_prediction, axis=1).numpy()\n",
        "test_prediction"
      ],
      "metadata": {
        "id": "fGayzoj9Bbp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = pd.DataFrame(test_prediction.T)\n",
        "predictions"
      ],
      "metadata": {
        "id": "0IUhclRgBnaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual_data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/data/final_data.csv')\n",
        "actua_data_big = pd.read_csv('/content/drive/My Drive/Colab Notebooks/data/final_data_1.csv')"
      ],
      "metadata": {
        "id": "ZJqdo2INBvk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_actual = pd.concat([actua_data_big, actual_data])\n",
        "data_actual = data_actual.drop_duplicates(subset = ['candidate_user_name', 'tweet'])\n",
        "data_actual.reset_index(inplace=True)"
      ],
      "metadata": {
        "id": "61MFDR4RBzq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_input, _ = tensor_inputs(data_actual['tweet'])"
      ],
      "metadata": {
        "id": "PClpk-YlB-nX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "miso_prediction = tf.nn.softmax(test_pred.logits)\n",
        "miso_prediction = tf.argmax(miso_prediction, axis=1).numpy()\n",
        "miso_prediction"
      ],
      "metadata": {
        "id": "_ByGB9JPCNxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_actual['Predicted'] = tf_prediction.T"
      ],
      "metadata": {
        "id": "8fCcgQEnCTWP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}